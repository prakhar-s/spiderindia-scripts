{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dae3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required modules\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.attrs import IS_PUNCT, LOWER\n",
    "import spacy\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import dateparser\n",
    "from dateparser.search import search_dates\n",
    "import requests\n",
    "from dateparser import parse\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85b56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cityPattern(city):\n",
    "    pattern = []\n",
    "    for b in city.split():\n",
    "        pattern.append({'LOWER':b})  \n",
    "    return pattern\n",
    "\n",
    "def buildPatterns(cities):\n",
    "    pattern = []\n",
    "    for city in cities:\n",
    "        pattern.append(cityPattern(city))\n",
    "    \n",
    "    return list(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23abfaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_match(matcher, doc, id, matches):\n",
    "    return matches\n",
    "\n",
    "def buildMatcher(patterns):\n",
    "    index=0;\n",
    "    for pattern in patterns:\n",
    "        if(pattern):\n",
    "            matcher.add(str(index),[pattern])\n",
    "            index+=1\n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164c6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cityMatcher(matcher, text):\n",
    "    cities = []\n",
    "    doc = nlp(text)\n",
    "    #for token in doc:\n",
    "        #print(token.text)\n",
    "    matches = matcher(doc)\n",
    "    for b in matches:\n",
    "        match_id, start, end = b\n",
    "        #print(b)\n",
    "        #print (doc[start : end])\n",
    "        cities.append(doc[start:end])\n",
    "    return cities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c57ab8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d82316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404566\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "file1 = open(\"placenames.txt\",\"r\")\n",
    "\n",
    "Lines = file1.readlines()\n",
    "setOfCities=set() \n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    if(line.strip().lower() not in stop_words):\n",
    "        setOfCities.add(line.strip().lower())\n",
    "        #cities.append(line.strip().lower())\n",
    "\n",
    "cities=list(setOfCities)\n",
    "print(len(cities))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4831b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patterns = buildPatterns(cities)\n",
    "print(patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a87deff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404566"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_matcher = buildMatcher(patterns)\n",
    "### Size of dictionary \n",
    "len(city_matcher)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef3d469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thakursar\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(cities[13])\n",
    "print(type(patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab062459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Castle Rock, Karnataka]\n",
      "Runtime of the program is 0.6874110698699951\n"
     ]
    }
   ],
   "source": [
    "import datefinder\n",
    "\n",
    "start = time.time()\n",
    "matchedCities=cityMatcher(city_matcher, \"Wall Crab Spider...Family Selenopidae ....Selenops or Makidopes ...Id Appreciated These spiders are very flat dorsoventrally..their running and striking speeds places them amongst the fastest in the world! Shot during the 4th SpiderIndia meet Castle Rock Karnataka Dec 19\")\n",
    "print(matchedCities)\n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705d7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates extraction through spacy ner follwed by dateparser\n",
    "\n",
    "def datesExtraction1(text):\n",
    "    dates=[]\n",
    "    if type(text) == str:\n",
    "        doc=nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            if(ent.label_==\"DATE\"):\n",
    "                date=dateparser.parse(ent.text)\n",
    "                if(date):\n",
    "                    dateString = date.strftime(\"%d-%b-%Y\")\n",
    "                    dates.append(dateString)\n",
    "    \n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "926fbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates extraction through only dateparser directly taling the input in the search_dates function\n",
    "\n",
    "def datesExtraction2(text):\n",
    "    dates=[]\n",
    "    results=search_dates(text)\n",
    "    if(results):\n",
    "        for result in results:\n",
    "            if(result):\n",
    "                date=result[1]\n",
    "                dateString=date.strftime(\"%d-%b-%Y\")\n",
    "                dates.append(dateString)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f418eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDates(text):\n",
    "    finalDates=[]\n",
    "    results=search_dates(text)\n",
    "    if(results):\n",
    "        for result in results:\n",
    "            dateFields={}\n",
    "            if(result):\n",
    "                verbatimDate=result[0]\n",
    "                if(parse(verbatimDate,settings={'REQUIRE_PARTS': ['day', 'month', 'year']})):\n",
    "                    parseDate=parse(verbatimDate,settings={'REQUIRE_PARTS': ['day', 'month', 'year']})\n",
    "                    dateFields[\"year\"]=parseDate.year\n",
    "                    dateFields[\"month\"]=parseDate.month\n",
    "                    dateFields[\"day\"]=parseDate.day\n",
    "                elif(parse(verbatimDate,settings={'REQUIRE_PARTS': ['month', 'year']})):\n",
    "                    parseDate=parse(verbatimDate,settings={'REQUIRE_PARTS': ['month', 'year']})\n",
    "                    dateFields[\"year\"]=parseDate.year\n",
    "                    dateFields[\"month\"]=parseDate.month\n",
    "                elif(parse(verbatimDate,settings={'REQUIRE_PARTS': ['day','month']})):\n",
    "                    parseDate=parse(verbatimDate,settings={'REQUIRE_PARTS': ['day','month']})\n",
    "                    dateFields[\"day\"]=parseDate.day\n",
    "                    dateFields[\"month\"]=parseDate.month\n",
    "                elif(parse(verbatimDate,settings={'REQUIRE_PARTS': ['year']})):\n",
    "                    parseDate=parse(verbatimDate,settings={'REQUIRE_PARTS': ['year']})\n",
    "                    dateFields[\"year\"]=parseDate.year\n",
    "                elif(parse(verbatimDate,settings={'REQUIRE_PARTS': ['month']})):\n",
    "                    parseDate=parse(verbatimDate,settings={'REQUIRE_PARTS': ['month']})\n",
    "                    dateFields[\"month\"]=parseDate.month\n",
    "                else:\n",
    "                    dateFields={}\n",
    "\n",
    "            if(dateFields):\n",
    "                finalDates.append(dateFields)                               \n",
    "        return finalDates\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a099913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names(namesArray):\n",
    "    if(not namesArray):\n",
    "        return []\n",
    "        \n",
    "    names=[]\n",
    "    for nameObject in namesArray:\n",
    "        names.append(nameObject['name'])\n",
    "    return names\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b8d5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of i = 708\n",
      "author = Abhijith Apc\n",
      "text=Do Jumping spider have Foresight ? Here is our latest paper on that !    Leaf suspension by a brooding female Epeus indicus (Araneae: Salticidae: Plexippina) in Karnataka Published in PECKHAMIA.  Check this… More link    https://peckhamia.com/peckhamia/PECKHAMIA_237.1.pdf  and know how a female Epeus Indicus can protect its brood .  You can also watch this youtube link for further details on same.  https://www.youtube.com/watch?v=zKWqqxYi-os ಇಂದಷ್ಟೇ ನಮ್ಮ ಒಂದು ಪ್ರಬಂಧ ಪೆಕೆಮಿಯಾ ಎಂಬ ಪತ್ರಿಕೆಯಲ್ಲಿ ಪ್ರಕಟವಾಗಿದೆ.  ವಿಷಯ :  ಜೇಡಗಳಿಗೂ ಮುಂದಾಲೋಚನೆ ಇದೆಯೇ ? ಹೌದು. ಎಪಿಯಸ್ ಎಂಬ ಜಿಗಿಯುವ ಜೇಡ , ತನ್ನ ಮರಿಗಳನ್ನು ರಕ್ಷಿಸಲು ಮಾಡಿದ ಉಪಾಯವೇ ಈ ಲೇಖನದ ತಿರುಳು.  ತನ್ನ ಮರಿಗಳಿದ್ದ ಎಲೆಯು ಹಳದಿಯಾಗಿ ಉದಿರಿ ಹೋಗುವುದು ಎಂದು ಮೊದಲೇ ಅರಿತ ಜೇಡ, ಆ ಎಲೆಯನ್ನು ಪಕ್ಕದ ಎಲೆಗೆ ಅಂಟಿಸುತ್ತದೆ. ಮುಂದೆ ಜೋರು ಗಾಳಿಗೆ ಎಲೆಯು ತೊಟ್ಟಿನಿಂದ ಕಳಚುತ್ತದೆ. ಮೊದಲೇ ಈ ಎಲೆಯನ್ನು ಭದ್ರ ಪಡಿಸಿದ್ದರಿಂದ ತನ್ನ ಸಂತತಿಗೆ ಯಾವ ಅಪಾಯವೂ  ಆಗುವುದಿಲ್ಲ.  ಅದರ ಸಂಪೂರ್ಣ ವರದಿ ಈ ಲೇಖನದಲ್ಲಿದೆ.      https://peckhamia.com/peckhamia/PECKHAMIA_237.1.pdf    ಯೂಟ್ಯೂಬಿನಲ್ಲಿ ವಿಡಿಯೋ ಕೋಡಾ ಇದೆ.  https://www.youtube.com/watch?v=zKWqqxYi-os\n",
      "permalink = https://m.facebook.com/groups/SpiderIndia/permalink/3964118303664091/?m_entstream_source=group&refid=18&_ft_=qid.-7369800145494774087%3Amf_story_key.3964118303664091%3Atop_level_post_id.3964118303664091%3Atl_objid.3964118303664091%3Acontent_owner_id_new.100000830662333%3Aoriginal_content_id.4036572789713703%3Aoriginal_content_owner_id.100000830662333%3Apage_id.175082879234338%3Asrc.22%3Astory_location.6%3Aattached_story_attachment_style.photo%3Afilter.GroupStoriesByActivityEntQuery%3Aott.AX-V5rNxc-1vGOg9%3Atds_flgs.3%3Apage_insights.%7B%22175082879234338%22%3A%7B%22page_id%22%3A175082879234338%2C%22page_id_type%22%3A%22group%22%2C%22actor_id%22%3A100000830662333%2C%22dm%22%3A%7B%22isShare%22%3A1%2C%22originalPostOwnerID%22%3A4036572789713703%7D%2C%22psn%22%3A%22EntGroupMallPostCreationStory%22%2C%22post_context%22%3A%7B%22object_fbtype%22%3A657%2C%22publish_time%22%3A1622623496%2C%22story_name%22%3A%22EntGroupMallPostCreationStory%22%2C%22story_fbid%22%3A%5B3964118303664091%5D%7D%2C%22role%22%3A1%2C%22sl%22%3A6%7D%7D&__tn__=-R\n",
      "Runtime of the program is 837.6475908756256\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "fields=[\"Author\",\"Desc\",\"Locations\",\"names\",\"Dates\",\"Permalink\"]\n",
    "filename = \"final_data_1.csv\"\n",
    "faultyPermalinksFilename=\"Faulty_Permalinks.csv\"\n",
    "faultyRow=[\"Author\",\"Desc\",\"Permalink\"]\n",
    "\n",
    "with open(filename, 'a') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)         \n",
    "    csvwriter.writerow(fields)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "df=pd.read_csv(\"/home/prakhar/combine_data/spiderindia_1.csv\")\n",
    "\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        text=df.loc[i,\"Desc\"]\n",
    "        author=df.loc[i,\"Author\"]\n",
    "        desc=df.loc[i,\"Desc\"]\n",
    "        permalink=df.loc[i,\"Permalink\"]\n",
    "        locations=[]\n",
    "        names=[]\n",
    "        dates2=[]\n",
    "        if(type(desc)==str):\n",
    "            locations=cityMatcher(city_matcher,desc.lower())\n",
    "            #ates1=datesExtraction1(desc)\n",
    "            dates2=extractDates(desc)\n",
    "            query = {'text':text}\n",
    "            response = requests.get('http://localhost:3006/parse',params=query)\n",
    "            names=extract_names(response.json()['names'])\n",
    "            #print(response.json()['names'])\n",
    "        row=[author,desc,locations,names,dates2,permalink]\n",
    "        with open(filename,'a') as csvfile1:\n",
    "            csvwriter1=csv.writer(csvfile1)\n",
    "            csvwriter1.writerow(row)\n",
    "    \n",
    "    except:\n",
    "        print(f\"value of i = {i}\")\n",
    "        print(f\"author = {author}\")\n",
    "        print(f\"text={text}\")\n",
    "        print(f\"permalink = {permalink}\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "       \n",
    "\n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cebf4acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "fields=[\"Author\",\"Desc\",\"Locations\",\"names\",\"Dates\",\"Permalink\"]\n",
    "filename = \"final_data_1.csv\"\n",
    "faultyPermalinksFilename=\"Faulty_Permalinks.csv\"\n",
    "faultyRow=[\"Author\",\"Desc\",\"Permalink\"]\n",
    "\n",
    "with open(filename, 'a') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)         \n",
    "    csvwriter.writerow(fields)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "df=pd.read_csv(\"/home/prakhar/combine_data/spiderindia_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bed7865",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'day'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e8cf2e1005af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'March'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'REQUIRE_PARTS'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'day'"
     ]
    }
   ],
   "source": [
    "#for date extraction and conversion to a standard format\n",
    "from dateparser import parse\n",
    "result=parse('March', settings={'REQUIRE_PARTS': [ 'month', 'year']})\n",
    "print(result.day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35aa612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gotcha\n"
     ]
    }
   ],
   "source": [
    "if( parse('December 2015', settings={'STRICT_PARSING': True})==None):\n",
    "    print(\"gotcha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c241ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIG\n",
      "\n",
      "1049182\n"
     ]
    }
   ],
   "source": [
    "#Flashtext algorithm testing\n",
    "\n",
    "from flashtext import KeywordProcessor\n",
    "keyword_processor = KeywordProcessor()\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "file1 = open(\"extended_placenames.txt\",\"r\")\n",
    "\n",
    "Lines = file1.readlines()\n",
    "setOfCities=set() \n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    if(line.strip().lower() not in stop_words):\n",
    "        if(line.strip().lower() not in setOfCities):\n",
    "            setOfCities.add(line.strip().lower())\n",
    "            keyword_processor.add_keyword(line.strip().lower())\n",
    "    if(line.strip().lower()==\"big\"):\n",
    "        print(line)\n",
    "            \n",
    "        #cities.append(line.strip().lower())\n",
    "\n",
    "        \n",
    "\n",
    "cities=list(setOfCities)\n",
    "print(len(cities))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e81b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prakhar/environments/my_env/lib/python3.6/site-packages/dateparser/date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n",
      "/home/prakhar/environments/my_env/lib/python3.6/site-packages/dateparser/freshness_date_parser.py:76: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  now = self.get_local_tz().localize(now)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of i = 708\n",
      "author = Abhijith Apc\n",
      "text=Do Jumping spider have Foresight ? Here is our latest paper on that !    Leaf suspension by a brooding female Epeus indicus (Araneae: Salticidae: Plexippina) in Karnataka Published in PECKHAMIA.  Check this… More link    https://peckhamia.com/peckhamia/PECKHAMIA_237.1.pdf  and know how a female Epeus Indicus can protect its brood .  You can also watch this youtube link for further details on same.  https://www.youtube.com/watch?v=zKWqqxYi-os ಇಂದಷ್ಟೇ ನಮ್ಮ ಒಂದು ಪ್ರಬಂಧ ಪೆಕೆಮಿಯಾ ಎಂಬ ಪತ್ರಿಕೆಯಲ್ಲಿ ಪ್ರಕಟವಾಗಿದೆ.  ವಿಷಯ :  ಜೇಡಗಳಿಗೂ ಮುಂದಾಲೋಚನೆ ಇದೆಯೇ ? ಹೌದು. ಎಪಿಯಸ್ ಎಂಬ ಜಿಗಿಯುವ ಜೇಡ , ತನ್ನ ಮರಿಗಳನ್ನು ರಕ್ಷಿಸಲು ಮಾಡಿದ ಉಪಾಯವೇ ಈ ಲೇಖನದ ತಿರುಳು.  ತನ್ನ ಮರಿಗಳಿದ್ದ ಎಲೆಯು ಹಳದಿಯಾಗಿ ಉದಿರಿ ಹೋಗುವುದು ಎಂದು ಮೊದಲೇ ಅರಿತ ಜೇಡ, ಆ ಎಲೆಯನ್ನು ಪಕ್ಕದ ಎಲೆಗೆ ಅಂಟಿಸುತ್ತದೆ. ಮುಂದೆ ಜೋರು ಗಾಳಿಗೆ ಎಲೆಯು ತೊಟ್ಟಿನಿಂದ ಕಳಚುತ್ತದೆ. ಮೊದಲೇ ಈ ಎಲೆಯನ್ನು ಭದ್ರ ಪಡಿಸಿದ್ದರಿಂದ ತನ್ನ ಸಂತತಿಗೆ ಯಾವ ಅಪಾಯವೂ  ಆಗುವುದಿಲ್ಲ.  ಅದರ ಸಂಪೂರ್ಣ ವರದಿ ಈ ಲೇಖನದಲ್ಲಿದೆ.      https://peckhamia.com/peckhamia/PECKHAMIA_237.1.pdf    ಯೂಟ್ಯೂಬಿನಲ್ಲಿ ವಿಡಿಯೋ ಕೋಡಾ ಇದೆ.  https://www.youtube.com/watch?v=zKWqqxYi-os\n",
      "permalink = https://m.facebook.com/groups/SpiderIndia/permalink/3964118303664091/?m_entstream_source=group&refid=18&_ft_=qid.-7369800145494774087%3Amf_story_key.3964118303664091%3Atop_level_post_id.3964118303664091%3Atl_objid.3964118303664091%3Acontent_owner_id_new.100000830662333%3Aoriginal_content_id.4036572789713703%3Aoriginal_content_owner_id.100000830662333%3Apage_id.175082879234338%3Asrc.22%3Astory_location.6%3Aattached_story_attachment_style.photo%3Afilter.GroupStoriesByActivityEntQuery%3Aott.AX-V5rNxc-1vGOg9%3Atds_flgs.3%3Apage_insights.%7B%22175082879234338%22%3A%7B%22page_id%22%3A175082879234338%2C%22page_id_type%22%3A%22group%22%2C%22actor_id%22%3A100000830662333%2C%22dm%22%3A%7B%22isShare%22%3A1%2C%22originalPostOwnerID%22%3A4036572789713703%7D%2C%22psn%22%3A%22EntGroupMallPostCreationStory%22%2C%22post_context%22%3A%7B%22object_fbtype%22%3A657%2C%22publish_time%22%3A1622623496%2C%22story_name%22%3A%22EntGroupMallPostCreationStory%22%2C%22story_fbid%22%3A%5B3964118303664091%5D%7D%2C%22role%22%3A1%2C%22sl%22%3A6%7D%7D&__tn__=-R\n",
      "Runtime of the program is 3343.1757509708405\n"
     ]
    }
   ],
   "source": [
    "#keywords_found = keyword_processor.extract_keywords(\"ID please. Nov'2021 Kohima, India.\")\n",
    "#print(keywords_found)\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "fields=[\"Author\",\"Desc\",\"Locations\",\"Scientific Names\",\"Dates\",\"Permalink\"]\n",
    "filename = \"Flashtext_Locations_Dates_Names_1.csv\"\n",
    "\n",
    "faultyPermalinksFilename=\"Faulty_Permalinks.csv\"\n",
    "faultyRow=[\"Author\",\"Desc\",\"Permalink\"]\n",
    "\n",
    "with open(filename, 'a') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)         \n",
    "    csvwriter.writerow(fields)\n",
    "    \n",
    "with open(faultyPermalinksFilename,'a') as faultyCsvFile:\n",
    "    fcsvwriter=csv.writer(faultyCsvFile)\n",
    "    fcsvwriter.writerow(faultyRow)\n",
    "\n",
    "df=pd.read_csv(\"/home/prakhar/combine_data/spiderindia_1.csv\")\n",
    "\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        text=df.loc[i,\"Desc\"]\n",
    "        author=df.loc[i,\"Author\"]\n",
    "        desc=df.loc[i,\"Desc\"]\n",
    "        permalink=df.loc[i,\"Permalink\"]\n",
    "        locations=[]\n",
    "        names=[]\n",
    "        dates2=[]\n",
    "        if(type(desc)==str):\n",
    "            locations=keyword_processor.extract_keywords(desc.lower())\n",
    "            dates2=extractDates(desc)\n",
    "            \n",
    "            query = {'text':text}\n",
    "            response = requests.get('http://localhost:3006/parse',params=query)\n",
    "            if(response.json()['names']):\n",
    "                names=extract_names(response.json()['names'])\n",
    "            \n",
    "        row=[author,desc,locations,names,dates2,permalink]\n",
    "        with open(filename,'a') as csvfile1:\n",
    "            csvwriter1=csv.writer(csvfile1)\n",
    "            csvwriter1.writerow(row)\n",
    "    \n",
    "    except:\n",
    "        print(f\"value of i = {i}\")\n",
    "        print(f\"author = {author}\")\n",
    "        print(f\"text={text}\")\n",
    "        print(f\"permalink = {permalink}\")\n",
    "        \n",
    "        errorRow=[author,text,permalink]\n",
    "        \n",
    "        with open(faultyPermalinksFilename,'a') as faultyCsvFile:\n",
    "            fcsvwriter=csv.writer(faultyCsvFile)\n",
    "            fcsvwriter.writerow(errorRow)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05dcf23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present\n"
     ]
    }
   ],
   "source": [
    "if 'one' in setOfCities:\n",
    "    print(\"present\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
